#
# Be aware that even a small syntax error here can lead to failures in output.
#

sidebar:
    about: True # set to False or comment line if you want to remove the "how to use?" in the sidebar
    education: True # set to False if you want education in main section instead of in sidebar

    # Profile information
    name: Ashok Ballolli
    tagline: Senior Data & MLOps Engineer
    avatar: profile.png  #place a 100x100 picture inside /assets/images/ folder and provide the name of the file below

    # Sidebar links
    # email: ballolliashok@gmail.com
    email: ashokb@engineer.com
    phone: +49-1605719293
    website: DataTe.ch #do not add http://
    linkedin: ashokballolli
    github: ashokballolli
    telegram: # add your nickname without '@' sign
    gitlab:
    bitbucket: ashokballolli
    twitter: '@ashok_ballolli'
    stack-overflow: # Number/Username, e.g. 123456/alandoe
    codewars:
    goodreads: # Number-Username, e.g. 123456-alandoe

    languages:
      - idiom: English
        level: Professional

      - idiom: Hindi
        level: Native

      - idiom: Kannada
        level: Native


career-profile:
    title: Career Profile
    summary: |
      Experienced Data/DataOps/MLOps Engineer with thorough hands on experience in all levels of software development life cycle. I am a hybrid Data Engineer, Software Developer, Automation Engineer. Supportive and enthusiastic team player dedicated to streamlining processes and efficiently resolving project issues. Willing to take ownership of core components.
education:
    - degree: B.E in Computer Science
      university: VTU(PDA College Of Engineering, Gulbarga)
      time: 2005 - 2009
experiences:
    - role: Senior Data & MLOps Engineer
      time: 01/2024 - Present
      company: Wayfair, Berlin/Germany
      details: |
          - Lead the productionization efforts for machine learning models using GCP Vertex Batch and Realtime services, ensuring seamless deployment and scalability in a production environment.
          - Collaborate closely with Data Scientists to provide curated datasets for model training, leveraging GCP's managed services for data preprocessing and post-processing tasks.
          - Serve as Subject Matter Expert (SME) for infrastructure architecture, implementing robust solutions for deployment, orchestration, and monitoring of ML pipelines and systems.
          - Establish and maintain robust monitoring and alerting systems, ensuring the reliability and performance of machine learning models and associated infrastructure.

    - role: Senior Data Engineer
      time: 05/2021 - Present
      company: Wayfair, Berlin/Germany
      details: |
          - Collaborating with stakeholders across the business to understand their data requirements.
          - Implemented the event driven ETL pipeline for processing the Google Analytics data using Apache Beam and GCP managed services.
          - Implemented the scalable realtime ETL pipelines using Apache Flink for processing Kafka events.
          - POC on different ETL tools and technologies.
          - Developed data dictionary using Google Data Catalog
          - Implemented CI/CD plugins to automate deployment of many GCP managed services.
          - Implemented Quality Checks framework for the pipelines running on Airflow.
          - Infrastructure provisioning thorough Terraform.
          - Participating in the design discussions, planning, estimation and retro meetings.

    - role: Senior Data Engineer
      time: 04/2020 - 04/2021
      company: Wefox, Berlin/Germany
      details: |
          - Migrated the legacy data infrastructure to the GCP utilising the GCP's serverless and managed services.
          - Migrated the VBA based ETL tool to Airflow.
          - Extract and Load setup using Xplenty.
          - Data migration and CDC using AWS DMS.
          - Built utilities in Scala & Python for processing structured and unstructured data from multiple data sources like API’s, S3, CSV, SFTP.
          - Gather and process raw data at scale (including writing scripts, web scraping, calling APIs, writing SQL queries and applications)
          - Built API’s using FastAPI.
          - Setting up of CI/CD pipeline using Github actions and Bash Scripts.
          - On-boarding the new MGA's with the necessary changes in the DWH and ETL.
          - Implemented realtime alerting for the data pipeline and services.
          - Developed the data dictionary.
          - Effective documentation about the applications, tools and utilities developed.
          - Creating high level design documents & source to target data mapping sheets.
          - POC on different ETL tools and technologies.
    - role: Data Automation Engineer
      time: 11/2017 - 03/2020
      company: Spotcap Global, Berlin/Germany
      details: |
          - Built data-pipeline in Scala & Python for processing structured and unstructured data from multiple data sources like API’s, Audit Tables, S3, which was then consumed by the data science team.
          - Gather and process raw data at scale (including writing scripts, web scraping, calling APIs, write SQL queries, writing applications)
          - Built API’s using Scala Play and Spring boot which acts as simulator for user journey and it’s actively used by the product, QA and data science team.
          - Developed a utility by implementing API’s and integrating with the Flock for pro- actively debugging the credit decision on user’s loan application.
          - Setting up of CI/CD pipeline (Jenkins integration) for the automation test suite.
          - Setting up the mocked data, which was critical during client demos and internal testing, and acted as POC for the mocked data services.
          - Built automation framework for Spotcap's backend API's from scratch.
          - Built load testing framework using Locust and Python.
          - Implemented real time alarming for the quality check failures to all the stake holders.
          - Effective documentation about the applications, tools and utilities developed.
    - role: Tech Lead
      time: 09/2015 - 11/2017
      company: OLA, Bangalore/India
      details: |
        - Worked on the application which served as a single source of truth for position/status of all cabs at any given point of time.
        - Design and architecture of tracking service.
        - Updating the Chef Cookbooks and Recipes and deploying the build on AWS-Cloud Environment.
        - Developed utilities to minimize the environment setup, for production sanity test and for debugging the issues in staging.
        - Application maintenance and troubleshooting.
        - Giving demos to the product team and Knowledge sharing sessions to the team.
        - Mentoring the junior team members.
    - role: Senior Software Engineer
      time: 11/2012 - 09/2015
      company: Altisource Labs, Bangalore/India
      details: |
        - Migration of existing code bases to AWS cloud.
        - Migration of SQL based searches to Apache SOLR based search.
        - Built a highly scalable and concurrent design by using multithreading principles and Rabbit MQ.
        - Implemented build and deployment process for the product using maven, jenkins etc.
        - Involved in the development of in house frame work and reusable components
        - Interacted with the business team to understand and analyze the requirements.
        - Designed the Creating Invoice, Creating Workflows Invoice Approval modules.
        - Worked on data integration, payment file generation and interfacing with 3rd party.
        - Worked with Support to resolve the production issues across the application.
        - Optimizing code for increased scalability.
        - Perform integration testing, system testing, regression testing.
        - Monitoring and scheduling Daemons.
        - Automation of test cases using Selenium Web driver, Sahi, Robot Framework and Shell script.
        - Setup Jasper Reports server
        - Wrote liquibase scripts, queries, stored procedures.
        - Wrote Shell scripts to automate payment files, deployment, server health monitoring.
        - Gave Demos, Knowledge sharing sessions to the team.
    - role: Software Engineer
      time: 09/2009 - 10/2012
      company: ZTE R&D Center, Kuala lumpur/Malaysia, Bangalore/India
      details: |
        - Preparing the system test cases, Test List and System Test Report.
        - Preparation of test environment and deployment.
        - Integration of all the third-party interfaces with RBT.
        - Execution of IOT test cases and resolving the inter communication issues with 3rd party modules.
        - Implementation and maintenance of matrices such as Test Matrix and Requirement Tractability Matrix.
        - Executing Sanity/Smoke test on new builds.
        - Preparing test reports for the system test performed.
        - Study the failures and checking server logs and Wireshark logs.
        - Installation of Linux, Database, tomcat, Jboss.
        - Preparing Test bed.
        - Upgrade/Migration testing.
        - Execution of UAT test cases.
        - Preparation of dual site environment for GR test and execution of test cases and preparation of document for GR to use at disaster condition.
projects:
    title: Projects
    intro: >
      You can list your side projects or open source libraries in this
      section. Lorem ipsum dolor sit amet, consectetur adipiscing elit.
      Vestibulum et ligula in nunc bibendum fringilla a eu lectus.
    assignments:
      - title: Velocity
        link: "#hook"
        tagline: "A responsive website template designed to help startups promote, market and sell their products."

      - title: DevStudio
        link: "#"
        tagline: "A responsive website template designed to help web developers/designers market their services."

      - title: Tempo
        link: "#"
        tagline: "A responsive website template designed to help startups promote their products or services and to attract users &amp; investors"

      - title: Atom
        link: "#"
        tagline: "A comprehensive website template solution for startups/developers to market their mobile apps."

      - title: Delta
        link: "#"
        tagline: "A responsive Bootstrap one page theme designed to help app developers promote their mobile apps"

publications:
    title: Publications
    intro: |
      You can list your publications in this section. Lorem ipsum dolor sit
      amet, consectetur adipiscing elit. Vestibulum et ligula in nunc
      bibendum fringilla a eu lectus.
    papers:
      - title: The Art of Computer Programming
        link: "#"
        authors: Donald E. Knuth
        conference: Addison-Wesley, 1968

      - title: "Genetic Programming III: Darwinian Invention &amp; Problem Solving"
        link: "#"
        authors: Koza, J.R., Andre, D., Bennett, F.H., Keane, M.A.
        conference: "Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1st edn. (1999)"

      - title: A syntax directed compiler for Algol 60
        link: "#"
        authors: Edgar T. Irons
        conference: "Comm. ACM 4 (1961), 51–55"

skills:
    title: Skills

    toolsets:
      - title: Languages & Frameworks
        link: "#"
        details: Python, Java, SQL, Fast API, Spring-boot, TestNG, ScalaTest, Shell/Bash script, Scala(Intermediate-level)

      - title: ELT & Data-Pipeline Tools
        link: "#"
        details: Apache Airflow, Apache Beam, Apache Flink, DBT, Xplenty, AWS DMS, Great expectations, Spark, Kafka

      - title: Cloud Services
        link: "#"
        details: GCP(Dataflow, Composer, BigQuery, Cloud Functions, Pub/Sub, DataCatalog, GCS, Vision AI), AWS(DMS, Redshift, RDS, Glue, Lambda, S3, Rekognition)

      - title: Databases
        link: "#"
        details: PostgreSQL, Oracle, MySQL, Elasticsearch, MongoDB, Redis, Memcache, RocksDB, Sybase

      - title: Technologies & Tools
        link: "#"
        details: Terraform, Kafka, Elasticsearch, Docker, Kubernetes, New Relic, Solr, RabbitMQ, Prometheus, Grafana, Graylog, Postman, Wireshark

      - title: Reporting Tools
        link: "#"
        details: PowerBI and Redash (Beginner to intermediate level of exp)

      - title: CI/CD & Automation Tools
        link: "#"
        details: Terraform, Github Actions, Jenkins, Buildkite, Selenium-Webdriver, RestAssured (API), Jacoco for code coverage

      - title: Load Testing Tools
        link: "#"
        details: Locust, Gatling and Wrk2

      - title: Version Management Tools & PMS
        link: "#"
        details: Git, JIRA
footer: >

